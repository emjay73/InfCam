<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="PAPER_TITLE - AUTHOR_NAMES">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="FIRST_AUTHOR_NAME, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <!-- <title>PAPER_TITLE - AUTHOR_NAMES | Academic Research</title> -->
  <title>FreeCam</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/camicon.jpg">
  <link rel="apple-touch-icon" href="static/images/camicon.jpg">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/camicon.jpg",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <!-- <h1 class="title is-2 publication-title">FreeCam: Camera Controlled Video Generation with Improved Pose Fidelity without Depth Prior</h1> -->
            <h1 class="title is-2 publication-title">FreeCam: Camera-Controlled Video Generation for High Pose Fidelity without Depth Priors</h1>            
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://emjay73.github.io/" target="_blank">Min-Jung Kim</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.co.kr/citations?user=4SCCBFwAAAAJ&hl=ko" target="_blank">Jeongho Kim</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.co.kr/citations?hl=ko&user=Jp-zhtUAAAAJ" target="_blank">Hoiyeong Jin</a>,</span>
                  </span>
                  <span class="author-block">
                    <a href="https://sites.google.com/site/jaegulchoo" target="_blank">Jaegul Choo</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <!-- <span class="author-block">KAIST<br>Arxiv</span> -->
                    <span class="author-block">KAIST</span>
                    <!-- TODO: Remove this line if no equal contribution -->
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper (Coming Soon)</span>
                      </a>
                    </span>

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- TODO: Replace with your teaser image -->
      <img src="static/images/teaser.jpg" alt="FreeCam teaser image" style="width: 100%; height: auto; max-height: 500px; object-fit: contain;">
      <!-- TODO: Replace with your video description -->
      <h2 class="subtitle has-text-left">
      </br>
        <!-- We introduce <strong><em>FreeCam</em></strong>, a depth-free, camera-controlled framework for novel-view video generation with unconstrained camera paths. 
        Using <em>infinite homography warping</em> and <em>AugMCV dataset</em>, 
        it yields low rotation/translation errors, high visual fidelity, generalizing from synthetic to real videos. -->
        <strong>FreeCam Results.</strong> Given a source video and a target camera trajectory, our method generates a video that faithfully follows the specified camera path. 
        With the reference coordinate system defined by the initial frame of the source video (highlighted in red), <em>FreeCam</em> enables novel-view video synthesis along arbitrary trajectories. 
        The examples show generated videos following backward (first) and arc (second) camera trajectories.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Novel-view video generation for dynamic scenes has emerged as a prominent direction alongside recent advances in video diffusion models. 
            Nevertheless, existing approaches exhibit limitations that reduce flexibility. 
            Methods that build on Image-to-Video models inherit biases from the base model, thereby constraining the target camera pose of the first frame to remain near the source. 
            The limited diversity of camera trajectories in available datasets further restricts learned models to a narrow range of motions. 
            While projection-based methods that rely on depth estimation do not impose explicit camera-pose constraints, they are susceptible to projection errors arising from depth warping.
          </br>
            To address these limitations, we present FreeCam, a depth-free, camera-controlled video-to-video generation framework supporting unconstrained camera paths. 
            <!-- To address these limitations, we present FreeCam, a depth-free, camera-controlled video-to-video framework for novel-view video generation with unconstrained camera paths.  -->            
            Our framework combines two key components: 
            infinite homography warping, which encodes 3D camera rotations directly in a 2D latent space to achieve high camera-pose fidelity; 
            and a data-augmentation pipeline that converts existing multi-view datasets into sequences with unbiased arbitrary trajectories and heterogeneous focal lengths, enabling training across diverse camera motions and focal settings.
          </br>
            <!-- On an evaluation set with unbiased, arbitrary camera poses, FreeCam achieves state-of-the-art trajectory accuracy while maintaining high visual fidelity, without any depth prior.  -->
            When evaluated on an unbiased test set with arbitrary camera poses, FreeCam achieves high camera-pose accuracy while maintaining high visual fidelity, without depth prior.
            Moreover, despite being trained exclusively on synthetic data, FreeCam generalizes well to real-world videos. 
            <!-- Ablation studies show that combining the proposed data-processing pipeline and infinite homography warping yields +5.46 dB PSNR (22.41% relative in dB scale; 18.91 → 24.37 dB on average). -->
            Ablation studies show that combining the proposed data-processing pipeline and infinite homography warping yields +5.46 dB PSNR on average.
            Comparative studies further indicate that FreeCam outperforms existing methods in trajectory accuracy (rotation accuracy +20.9% and translation accuracy +38.0%) while maintaining high visual fidelity.
            <!-- establishing a framework for precise and flexible camera-motion control in video synthesis () -->
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Video Gallery -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Qualitative Results (In-the-Wild)</h2>
      <div class="columns is-multiline">
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Ours_Grid_FF-Async_In-the-wild_1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Ours_Grid_FF-Async_In-the-wild_2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Ours_Grid_FF-Async_In-the-wild_3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Qualitative Results (WebVid Dataset)</h2>
      <div class="columns is-multiline">
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Ours_Grid_FF-Async_WebVid_3.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Ours_Grid_FF-Async_WebVid_4.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Ours_Grid_FF-Async_WebVid_5.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Ours_Grid_FF-Async_WebVid_6.mp4" type="video/mp4">
          </video>
        </div>
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Ours_Grid_FF-Sync_WebVid_1.mp4" type="video/mp4">
          </video>
        </div>                
      </div>

    </div>
  </div>
</section>
<!-- End video gallery -->


<!-- Comparison with Other Methods Gallery -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Comparison with Other Methods (Synthetic Dataset)</h2>
      <div class="columns is-multiline">
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Comparison_FF-Async_AugMCV.mp4" type="video/mp4">
          </video>
        </div>                      
      </div>      
    </div>
  </div>
</section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Comparison with Other Methods (WebVid Dataset)</h2>
      <div class="columns is-multiline">
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Comparison_FF-Async.mp4" type="video/mp4">
          </video>
        </div>   
        <div class="column is-full">
          <video autoplay muted loop style="width: 100%; height: auto;">
            <source src="static/videos/Comparison_FF-Sync.mp4" type="video/mp4">
          </video>
        </div>                          
      </div>    
      
    </div>
  </div>
</section>
<!-- End comparison gallery -->


<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
